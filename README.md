# Sensitive-Data-Identifier

## Overview

This repository contains code for an Open Source Machine Learning (ML) Application Logs Analyzer. The purpose of this tool is to analyze logs generated by open source ML applications, such as Apache Spark, to identify instances of private information being logged. It can help ensure the privacy and security of users' data by flagging potential data leakage.

## Contents

- [Introduction](#open-source-ml-application-logs-analyzer)
- [Getting Started](#getting-started)
- [Features](#features)
- [Usage](#usage)

  
## Getting Started

These instructions will help you get started with using and contributing to the project.

### Prerequisites

- Python 3.6+
- [Presidio Analyzer](https://github.com/microsoft/presidio)
- [Presidio Anonymizer](https://github.com/microsoft/presidio-anonymizer)


## Features

- Analyze logs of open source ML applications to identify potential privacy breaches.
- Detect and report instances of private data such as credit card numbers, social security numbers, and more.
- Anonymize sensitive information in logs to improve privacy.
- Supports multiple programming languages used in open source ML applications.

## Usage

1. Prepare your log data by placing it in a text file (e.g., `CustSeg-Logs.txt`).

2. Configure the `entities` and `language` parameters in the script to match the sensitive information and language used in your logs.

3. Run the script to analyze the log data:

   ```bash
   python temp.py
   ```

4. The script will output the analysis results, including any identified sensitive information.

   ```plaintext
   {
       'results': [
           {
               'char': 200,
               'entity_type': 'CREDIT_CARD',
               'score': 0.9375255410630697,
               'text': '1234 5678 9012 3456',
           },
           {
               'char': 432,
               'entity_type': 'US_SSN',
               'score': 0.987654321,
               'text': '123-45-6789',
           },
           {
               'char': 1000,
               'entity_type': 'NRP',
               'score': 0.854321,
               'text': 'NRP123456',
           },
           # More results...
       ],
   }
   ```

5. Anonymize the log data to protect privacy (uncomment the relevant code in the script).

6. Update the script and configuration to match your specific log format and use case.
